input {
    # JDBC ###########################
    # Test jdbc connection string using sqlline
    # Here we're setting params of:
    # - useSSL=false
    # - useCursorFetch=true
    # - to use cursor fetch must set jdbc_fetch_size
    # -- still experimenting with this
    # -- idea is to avoid JavaHeapMemory issues
    # ################################
    jdbc {
        jdbc_connection_string => "jdbc:mysql://${MYSQL_HOST:localhost}:3306/mongoliaCatalog_2.0?useSSL=false&useCursorFetch=true"
        jdbc_user => "root"
        jdbc_password => "4thebenefitof@LL"
        jdbc_driver_library => "/etc/logstash/tools/mysql-connector-java-5.1.46-bin.jar"
        jdbc_driver_class => "com.mysql.jdbc.Driver"
        jdbc_fetch_size => "100"
        statement => "
        SELECT authTib, ttlTib, ttlTibBrf, ttlEng, ttlSkt, convert(colophon using utf8) 
        FROM mongoliaCombinedCatalog
        WHERE catNoNorm = 'M0007651'
        "
    }
}
# OUTPUT ###########################
# Sending output directly to elasticsearch
# if we set document_id, then we can update based on id
# ex. we can import additional docs with conditional like,
# create doc only if document_id does not exist...
# ###################################
output {
    stdout { codec => json_lines }
    elasticsearch {
        hosts => ["${ES_HOST:157.230.172.69}:9200"]
        index => "${ES_INDEX:acip_update_2}"
        document_id => "%{catref}"
    }
}