input {
    # JDBC ###########################
    # Test jdbc connection string using sqlline
    # Here we're setting params of:
    # - useSSL=false
    # - useCursorFetch=true
    # - to use cursor fetch must set jdbc_fetch_size
    # -- still experimenting with this
    # -- idea is to avoid JavaHeapMemory issues
    # ################################
    jdbc {
        jdbc_connection_string => "jdbc:mysql://localhost:3306/acipmaintenance?useSSL=false&useCursorFetch=true"
        jdbc_user => "root"
        jdbc_password => "4thebenefitof@LL"
        jdbc_driver_library => "/etc/logstash/tools/mysql-connector-java-5.1.46-bin.jar"
        jdbc_driver_class => "com.mysql.jdbc.Driver"
        jdbc_fetch_size => "100"
        statement => "
        select
            acip.catRef,
            CONVERT(uncompress(data.Data) USING 'utf8') as tibText,
            acip.catalogNumber, acip.collection, acip.byteCount,
            acip.chkLevel, acip.catalogingStatus, acip.titleEng,
            acip.titleSkt, acip.titleTib, acip.authorDates,
            acip.authorEng, acip.authorSkt, acip.authorTib
        from acipmaintenance.aciptbl as acip
            left join acipmaintenance.aciptbldata as data
            on (acip.catRef = data.CatRef)
        where acip.collection in ('KG') and acip.catRef between 94600 and 94620;
        "
    }
}
# OUTPUT ###########################
# Sending output directly to elasticsearch
# if we set document_id, then we can update based on id
# ex. we can import additional docs with conditional like,
# create doc only if document_id does not exist...
# ###################################
output {
    stdout { codec => json_lines }
    elasticsearch {
        hosts => ["${HOST:157.230.172.69}:9200"]
        index => "acip_update"
        document_id => "%{catref}"
    }
}